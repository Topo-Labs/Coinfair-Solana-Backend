use crate::{config::EventListenerConfig, error::Result};
use std::{
    collections::HashMap,
    sync::{
        atomic::{AtomicU64, Ordering},
        Arc,
    },
    time::{Duration, Instant},
};
use sysinfo::System;
use tokio::{sync::RwLock, time::interval};
use tracing::{debug, error, info, warn};

/// æŒ‡æ ‡ç±»å‹
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum MetricType {
    /// è®¡æ•°å™¨ - åªèƒ½å¢åŠ 
    Counter,
    /// æµ‹é‡å™¨ - å¯ä»¥å¢å‡
    Gauge,
    /// ç›´æ–¹å›¾ - è®°å½•åˆ†å¸ƒ
    Histogram,
    /// æ‘˜è¦ - ç»Ÿè®¡ä¿¡æ¯
    Summary,
}

/// æŒ‡æ ‡æ•°æ®ç‚¹
#[derive(Debug, Clone)]
pub struct MetricData {
    /// æŒ‡æ ‡åç§°
    pub name: String,
    /// æŒ‡æ ‡ç±»å‹
    pub metric_type: MetricType,
    /// æŒ‡æ ‡å€¼
    pub value: f64,
    /// æ—¶é—´æˆ³
    pub timestamp: Instant,
    /// æ ‡ç­¾
    pub labels: HashMap<String, String>,
    /// æè¿°
    pub description: String,
}

impl MetricData {
    /// åˆ›å»ºæ–°çš„æŒ‡æ ‡æ•°æ®ç‚¹
    pub fn new(name: String, metric_type: MetricType, value: f64, description: String) -> Self {
        Self {
            name,
            metric_type,
            value,
            timestamp: Instant::now(),
            labels: HashMap::new(),
            description,
        }
    }

    /// æ·»åŠ æ ‡ç­¾
    pub fn with_label(mut self, key: String, value: String) -> Self {
        self.labels.insert(key, value);
        self
    }

    /// æ·»åŠ å¤šä¸ªæ ‡ç­¾
    pub fn with_labels(mut self, labels: HashMap<String, String>) -> Self {
        self.labels.extend(labels);
        self
    }
}

/// æŒ‡æ ‡æ”¶é›†å™¨
///
/// è´Ÿè´£:
/// - æ”¶é›†å„ç§ç³»ç»ŸæŒ‡æ ‡
/// - æä¾›æŒ‡æ ‡æŸ¥è¯¢æ¥å£
/// - å®šæœŸæŠ¥å‘Šç³»ç»ŸçŠ¶æ€
/// - ç›‘æ§æ€§èƒ½å’Œå¥åº·çŠ¶æ€
pub struct MetricsCollector {
    config: Arc<EventListenerConfig>,

    // è¿è¡ŒçŠ¶æ€
    is_running: Arc<RwLock<bool>>,

    // æ ¸å¿ƒæŒ‡æ ‡è®¡æ•°å™¨
    events_processed: Arc<AtomicU64>,
    events_failed: Arc<AtomicU64>,
    websocket_connections: Arc<AtomicU64>,
    websocket_reconnections: Arc<AtomicU64>,
    batch_writes: Arc<AtomicU64>,
    checkpoint_saves: Arc<AtomicU64>,

    // æ€§èƒ½æŒ‡æ ‡
    processing_durations: Arc<RwLock<Vec<Duration>>>,
    websocket_latencies: Arc<RwLock<Vec<Duration>>>,
    batch_write_durations: Arc<RwLock<Vec<Duration>>>,

    // ç³»ç»ŸæŒ‡æ ‡
    start_time: Instant,
    last_metrics_report: Arc<RwLock<Option<Instant>>>,
    system_monitor: Arc<RwLock<System>>,

    // è‡ªå®šä¹‰æŒ‡æ ‡å­˜å‚¨
    custom_metrics: Arc<RwLock<HashMap<String, MetricData>>>,
}

/// æŒ‡æ ‡ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone, serde::Serialize)]
pub struct MetricsStats {
    pub uptime_seconds: u64,
    pub events_processed: u64,
    pub events_failed: u64,
    pub success_rate: f64,
    pub websocket_connections: u64,
    pub websocket_reconnections: u64,
    pub batch_writes: u64,
    pub checkpoint_saves: u64,
    pub avg_processing_duration_ms: f64,
    pub avg_websocket_latency_ms: f64,
    pub avg_batch_write_duration_ms: f64,
    pub is_running: bool,
    #[serde(skip)]
    pub last_metrics_report: Option<Instant>,
    pub custom_metrics_count: usize,
}

/// æ€§èƒ½æŠ¥å‘Š
#[derive(Debug, Clone, serde::Serialize)]
pub struct PerformanceReport {
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub uptime_seconds: u64,
    pub events_per_second: f64,
    pub batches_per_minute: f64,
    pub avg_processing_time_ms: f64,
    pub error_rate: f64,
    pub websocket_health: WebSocketHealth,
    pub database_health: DatabaseHealth,
    pub system_resources: SystemResources,
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct WebSocketHealth {
    pub is_connected: bool,
    pub connections_count: u64,
    pub reconnections_count: u64,
    pub avg_latency_ms: f64,
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct DatabaseHealth {
    pub batch_writes_count: u64,
    pub avg_write_duration_ms: f64,
    pub checkpoint_saves_count: u64,
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct SystemResources {
    pub memory_usage_mb: f64,
    pub cpu_usage_percent: f64,
}

impl MetricsCollector {
    /// åˆ›å»ºæ–°çš„æŒ‡æ ‡æ”¶é›†å™¨
    pub fn new(config: &EventListenerConfig) -> Result<Self> {
        let config = Arc::new(config.clone());

        // åˆå§‹åŒ–ç³»ç»Ÿç›‘æ§
        let mut system = System::new_all();
        system.refresh_all();

        Ok(Self {
            config,
            is_running: Arc::new(RwLock::new(false)),
            events_processed: Arc::new(AtomicU64::new(0)),
            events_failed: Arc::new(AtomicU64::new(0)),
            websocket_connections: Arc::new(AtomicU64::new(0)),
            websocket_reconnections: Arc::new(AtomicU64::new(0)),
            batch_writes: Arc::new(AtomicU64::new(0)),
            checkpoint_saves: Arc::new(AtomicU64::new(0)),
            processing_durations: Arc::new(RwLock::new(Vec::new())),
            websocket_latencies: Arc::new(RwLock::new(Vec::new())),
            batch_write_durations: Arc::new(RwLock::new(Vec::new())),
            start_time: Instant::now(),
            last_metrics_report: Arc::new(RwLock::new(None)),
            system_monitor: Arc::new(RwLock::new(system)),
            custom_metrics: Arc::new(RwLock::new(HashMap::new())),
        })
    }

    /// å¯åŠ¨æŒ‡æ ‡æ”¶é›†
    pub async fn start_collection(&self) -> Result<()> {
        let mut is_running = self.is_running.write().await;
        if *is_running {
            warn!("æŒ‡æ ‡æ”¶é›†å™¨å·²åœ¨è¿è¡Œä¸­");
            return Ok(());
        }
        *is_running = true;
        drop(is_running);

        info!("ğŸ“Š å¯åŠ¨æŒ‡æ ‡æ”¶é›†");

        let collector = self.clone();
        let metrics_interval = self.config.get_metrics_interval();

        tokio::spawn(async move {
            let mut interval = interval(metrics_interval);

            while *collector.is_running.read().await {
                interval.tick().await;

                if let Err(e) = collector.collect_and_report_metrics().await {
                    error!("âŒ æŒ‡æ ‡æ”¶é›†å’ŒæŠ¥å‘Šå¤±è´¥: {}", e);
                }
            }

            info!("ğŸ“Š æŒ‡æ ‡æ”¶é›†å·²åœæ­¢");
        });

        Ok(())
    }

    /// åœæ­¢æŒ‡æ ‡æ”¶é›†
    pub async fn stop(&self) -> Result<()> {
        info!("ğŸ›‘ åœæ­¢æŒ‡æ ‡æ”¶é›†å™¨");
        let mut is_running = self.is_running.write().await;
        *is_running = false;
        Ok(())
    }

    /// è®°å½•äº‹ä»¶å¤„ç†æˆåŠŸ - æ”¯æŒå¤šç¨‹åºæ ‡ç­¾
    pub async fn record_event_processed(&self) -> Result<()> {
        self.events_processed.fetch_add(1, Ordering::Relaxed);
        debug!("ğŸ“ˆ è®°å½•äº‹ä»¶å¤„ç†æˆåŠŸ");
        Ok(())
    }

    /// è®°å½•ç‰¹å®šç¨‹åºçš„äº‹ä»¶å¤„ç†æˆåŠŸ
    pub async fn record_event_processed_for_program(&self, program_id: &str) -> Result<()> {
        self.events_processed.fetch_add(1, Ordering::Relaxed);

        // åˆ›å»ºå¸¦æœ‰ç¨‹åºIDæ ‡ç­¾çš„æŒ‡æ ‡
        let metric = MetricData::new(
            "events_processed_by_program".to_string(),
            MetricType::Counter,
            1.0,
            "Events processed by specific program".to_string(),
        )
        .with_label("program_id".to_string(), program_id.to_string());

        self.add_custom_metric(metric).await?;
        debug!("ğŸ“ˆ è®°å½•ç¨‹åº{}äº‹ä»¶å¤„ç†æˆåŠŸ", program_id);
        Ok(())
    }

    /// è®°å½•äº‹ä»¶å¤„ç†å¤±è´¥
    pub async fn record_event_failed(&self) -> Result<()> {
        self.events_failed.fetch_add(1, Ordering::Relaxed);
        debug!("ğŸ“‰ è®°å½•äº‹ä»¶å¤„ç†å¤±è´¥");
        Ok(())
    }

    /// è®°å½•ç‰¹å®šç¨‹åºçš„äº‹ä»¶å¤„ç†å¤±è´¥
    pub async fn record_event_failed_for_program(&self, program_id: &str, error: &str) -> Result<()> {
        self.events_failed.fetch_add(1, Ordering::Relaxed);

        // åˆ›å»ºå¸¦æœ‰ç¨‹åºIDå’Œé”™è¯¯ç±»å‹æ ‡ç­¾çš„æŒ‡æ ‡
        let metric = MetricData::new(
            "events_failed_by_program".to_string(),
            MetricType::Counter,
            1.0,
            "Events failed by specific program".to_string(),
        )
        .with_label("program_id".to_string(), program_id.to_string())
        .with_label("error_type".to_string(), error.to_string());

        self.add_custom_metric(metric).await?;
        debug!("ğŸ“‰ è®°å½•ç¨‹åº{}äº‹ä»¶å¤„ç†å¤±è´¥: {}", program_id, error);
        Ok(())
    }

    /// è®°å½•äº‹ä»¶å¤„ç†è€—æ—¶
    pub async fn record_processing_duration(&self, duration: Duration) -> Result<()> {
        let mut durations = self.processing_durations.write().await;
        durations.push(duration);

        // ä¿æŒæœ€è¿‘1000ä¸ªæ ·æœ¬
        if durations.len() > 1000 {
            durations.remove(0);
        }

        debug!("â±ï¸ è®°å½•å¤„ç†è€—æ—¶: {:?}", duration);
        Ok(())
    }

    /// è®°å½•WebSocketè¿æ¥
    pub async fn record_websocket_connection(&self) -> Result<()> {
        self.websocket_connections.fetch_add(1, Ordering::Relaxed);
        debug!("ğŸ”Œ è®°å½•WebSocketè¿æ¥");
        Ok(())
    }

    /// è®°å½•WebSocketé‡è¿
    pub async fn record_websocket_reconnection(&self) -> Result<()> {
        self.websocket_reconnections.fetch_add(1, Ordering::Relaxed);
        debug!("ğŸ”„ è®°å½•WebSocketé‡è¿");
        Ok(())
    }

    /// è®°å½•WebSocketå»¶è¿Ÿ
    pub async fn record_websocket_latency(&self, latency: Duration) -> Result<()> {
        let mut latencies = self.websocket_latencies.write().await;
        latencies.push(latency);

        // ä¿æŒæœ€è¿‘1000ä¸ªæ ·æœ¬
        if latencies.len() > 1000 {
            latencies.remove(0);
        }

        debug!("ğŸ“¡ è®°å½•WebSocketå»¶è¿Ÿ: {:?}", latency);
        Ok(())
    }

    /// è®°å½•æ‰¹é‡å†™å…¥
    pub async fn record_batch_write(&self) -> Result<()> {
        self.batch_writes.fetch_add(1, Ordering::Relaxed);
        debug!("ğŸ’¾ è®°å½•æ‰¹é‡å†™å…¥");
        Ok(())
    }

    /// è®°å½•æ‰¹é‡å†™å…¥è€—æ—¶
    pub async fn record_batch_write_duration(&self, duration: Duration) -> Result<()> {
        let mut durations = self.batch_write_durations.write().await;
        durations.push(duration);

        // ä¿æŒæœ€è¿‘1000ä¸ªæ ·æœ¬
        if durations.len() > 1000 {
            durations.remove(0);
        }

        debug!("ğŸ’½ è®°å½•æ‰¹é‡å†™å…¥è€—æ—¶: {:?}", duration);
        Ok(())
    }

    /// è®°å½•æ£€æŸ¥ç‚¹ä¿å­˜
    pub async fn record_checkpoint_save(&self) -> Result<()> {
        self.checkpoint_saves.fetch_add(1, Ordering::Relaxed);
        debug!("ğŸ’¾ è®°å½•æ£€æŸ¥ç‚¹ä¿å­˜");
        Ok(())
    }

    /// è®°å½•æ¸…ç†å‘¨æœŸ
    pub async fn record_cleanup_cycle(&self) -> Result<()> {
        // å¯ä»¥åœ¨è¿™é‡Œè®°å½•æ¸…ç†ç›¸å…³çš„æŒ‡æ ‡
        debug!("ğŸ§¹ è®°å½•æ¸…ç†å‘¨æœŸ");
        Ok(())
    }

    /// æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡
    pub async fn add_custom_metric(&self, metric: MetricData) -> Result<()> {
        let mut metrics = self.custom_metrics.write().await;
        metrics.insert(metric.name.clone(), metric);
        debug!("ğŸ“Š æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡");
        Ok(())
    }

    /// æ›´æ–°è‡ªå®šä¹‰æŒ‡æ ‡
    pub async fn update_custom_metric(&self, name: &str, value: f64) -> Result<()> {
        let mut metrics = self.custom_metrics.write().await;
        if let Some(metric) = metrics.get_mut(name) {
            metric.value = value;
            metric.timestamp = Instant::now();
            debug!("ğŸ“Š æ›´æ–°è‡ªå®šä¹‰æŒ‡æ ‡: {} = {}", name, value);
        } else {
            warn!("âš ï¸ è‡ªå®šä¹‰æŒ‡æ ‡ä¸å­˜åœ¨: {}", name);
        }
        Ok(())
    }

    /// æ”¶é›†å¹¶æŠ¥å‘ŠæŒ‡æ ‡
    async fn collect_and_report_metrics(&self) -> Result<()> {
        if !self.config.monitoring.enable_performance_monitoring {
            return Ok(());
        }

        let stats = self.get_stats().await?;
        let report = self.generate_performance_report().await?;

        // æ›´æ–°æœ€åæŠ¥å‘Šæ—¶é—´
        {
            let mut last_report = self.last_metrics_report.write().await;
            *last_report = Some(Instant::now());
        }

        info!(
            "ğŸ“Š æ€§èƒ½æŠ¥å‘Š - è¿è¡Œæ—¶é—´: {}s, å¤„ç†äº‹ä»¶: {}, æˆåŠŸç‡: {:.2}%, å¹³å‡å¤„ç†æ—¶é—´: {:.2}ms",
            stats.uptime_seconds,
            stats.events_processed,
            stats.success_rate * 100.0,
            stats.avg_processing_duration_ms
        );

        if report.error_rate > 0.1 {
            // é”™è¯¯ç‡è¶…è¿‡10%
            warn!("âš ï¸ é«˜é”™è¯¯ç‡æ£€æµ‹: {:.2}%", report.error_rate * 100.0);
        }

        if report.avg_processing_time_ms > 1000.0 {
            // å¹³å‡å¤„ç†æ—¶é—´è¶…è¿‡1ç§’
            warn!("âš ï¸ é«˜å¤„ç†å»¶è¿Ÿæ£€æµ‹: {:.2}ms", report.avg_processing_time_ms);
        }

        Ok(())
    }

    /// ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    pub async fn generate_performance_report(&self) -> Result<PerformanceReport> {
        let uptime = self.start_time.elapsed().as_secs();
        let events_processed = self.events_processed.load(Ordering::Relaxed);
        let events_failed = self.events_failed.load(Ordering::Relaxed);
        let total_events = events_processed + events_failed;

        let events_per_second = if uptime > 0 {
            events_processed as f64 / uptime as f64
        } else {
            0.0
        };

        let batches_per_minute = if uptime > 0 {
            let batch_writes = self.batch_writes.load(Ordering::Relaxed);
            (batch_writes as f64 / uptime as f64) * 60.0
        } else {
            0.0
        };

        let error_rate = if total_events > 0 {
            events_failed as f64 / total_events as f64
        } else {
            0.0
        };

        // è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
        let avg_processing_time_ms = {
            let durations = self.processing_durations.read().await;
            if durations.is_empty() {
                0.0
            } else {
                let total: Duration = durations.iter().sum();
                total.as_millis() as f64 / durations.len() as f64
            }
        };

        // WebSocketå¥åº·çŠ¶æ€
        let websocket_health = WebSocketHealth {
            is_connected: true, // è¿™é‡Œåº”è¯¥ä»WebSocketç®¡ç†å™¨è·å–å®é™…çŠ¶æ€
            connections_count: self.websocket_connections.load(Ordering::Relaxed),
            reconnections_count: self.websocket_reconnections.load(Ordering::Relaxed),
            avg_latency_ms: {
                let latencies = self.websocket_latencies.read().await;
                if latencies.is_empty() {
                    0.0
                } else {
                    let total: Duration = latencies.iter().sum();
                    total.as_millis() as f64 / latencies.len() as f64
                }
            },
        };

        // æ•°æ®åº“å¥åº·çŠ¶æ€
        let database_health = DatabaseHealth {
            batch_writes_count: self.batch_writes.load(Ordering::Relaxed),
            avg_write_duration_ms: {
                let durations = self.batch_write_durations.read().await;
                if durations.is_empty() {
                    0.0
                } else {
                    let total: Duration = durations.iter().sum();
                    total.as_millis() as f64 / durations.len() as f64
                }
            },
            checkpoint_saves_count: self.checkpoint_saves.load(Ordering::Relaxed),
        };

        // è·å–çœŸå®çš„ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        let system_resources = {
            let mut system = self.system_monitor.write().await;
            // åˆ·æ–°ç³»ç»Ÿä¿¡æ¯ä»¥è·å–æœ€æ–°æ•°æ®
            system.refresh_cpu();
            system.refresh_memory();

            // è®¡ç®—å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰
            let memory_usage_mb = system.used_memory() as f64 / 1024.0 / 1024.0;

            // è®¡ç®—CPUä½¿ç”¨ç‡ï¼ˆå¹³å‡å€¼ï¼‰
            let cpu_usage_percent = if system.cpus().is_empty() {
                0.0
            } else {
                system.cpus().iter().map(|cpu| cpu.cpu_usage()).sum::<f32>() as f64 / system.cpus().len() as f64
            };

            SystemResources {
                memory_usage_mb,
                cpu_usage_percent,
            }
        };

        Ok(PerformanceReport {
            timestamp: chrono::Utc::now(),
            uptime_seconds: uptime,
            events_per_second,
            batches_per_minute,
            avg_processing_time_ms,
            error_rate,
            websocket_health,
            database_health,
            system_resources,
        })
    }

    /// è·å–æŒ‡æ ‡ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_stats(&self) -> Result<MetricsStats> {
        let uptime = self.start_time.elapsed().as_secs();
        let events_processed = self.events_processed.load(Ordering::Relaxed);
        let events_failed = self.events_failed.load(Ordering::Relaxed);
        let total_events = events_processed + events_failed;

        let success_rate = if total_events > 0 {
            events_processed as f64 / total_events as f64
        } else {
            1.0
        };

        let avg_processing_duration_ms = {
            let durations = self.processing_durations.read().await;
            if durations.is_empty() {
                0.0
            } else {
                let total: Duration = durations.iter().sum();
                total.as_millis() as f64 / durations.len() as f64
            }
        };

        let avg_websocket_latency_ms = {
            let latencies = self.websocket_latencies.read().await;
            if latencies.is_empty() {
                0.0
            } else {
                let total: Duration = latencies.iter().sum();
                total.as_millis() as f64 / latencies.len() as f64
            }
        };

        let avg_batch_write_duration_ms = {
            let durations = self.batch_write_durations.read().await;
            if durations.is_empty() {
                0.0
            } else {
                let total: Duration = durations.iter().sum();
                total.as_millis() as f64 / durations.len() as f64
            }
        };

        let custom_metrics_count = {
            let metrics = self.custom_metrics.read().await;
            metrics.len()
        };

        Ok(MetricsStats {
            uptime_seconds: uptime,
            events_processed,
            events_failed,
            success_rate,
            websocket_connections: self.websocket_connections.load(Ordering::Relaxed),
            websocket_reconnections: self.websocket_reconnections.load(Ordering::Relaxed),
            batch_writes: self.batch_writes.load(Ordering::Relaxed),
            checkpoint_saves: self.checkpoint_saves.load(Ordering::Relaxed),
            avg_processing_duration_ms,
            avg_websocket_latency_ms,
            avg_batch_write_duration_ms,
            is_running: *self.is_running.read().await,
            last_metrics_report: *self.last_metrics_report.read().await,
            custom_metrics_count,
        })
    }

    /// é‡ç½®æ‰€æœ‰æŒ‡æ ‡
    pub async fn reset_metrics(&self) -> Result<()> {
        info!("ğŸ”„ é‡ç½®æ‰€æœ‰æŒ‡æ ‡");

        self.events_processed.store(0, Ordering::Relaxed);
        self.events_failed.store(0, Ordering::Relaxed);
        self.websocket_connections.store(0, Ordering::Relaxed);
        self.websocket_reconnections.store(0, Ordering::Relaxed);
        self.batch_writes.store(0, Ordering::Relaxed);
        self.checkpoint_saves.store(0, Ordering::Relaxed);

        {
            let mut durations = self.processing_durations.write().await;
            durations.clear();
        }

        {
            let mut latencies = self.websocket_latencies.write().await;
            latencies.clear();
        }

        {
            let mut durations = self.batch_write_durations.write().await;
            durations.clear();
        }

        {
            let mut metrics = self.custom_metrics.write().await;
            metrics.clear();
        }

        {
            let mut last_report = self.last_metrics_report.write().await;
            *last_report = None;
        }

        Ok(())
    }

    /// å¯¼å‡ºæŒ‡æ ‡ä¸ºPrometheusæ ¼å¼ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
    pub async fn export_prometheus_metrics(&self) -> Result<String> {
        let stats = self.get_stats().await?;
        let report = self.generate_performance_report().await?;

        let mut output = String::new();

        // åŸºç¡€æ ‡ç­¾ - åŠ¨æ€è·å–ç‰ˆæœ¬å·
        let service_labels = "service=\"event-listener\"";
        let version_labels = format!("version=\"{}\"", env!("CARGO_PKG_VERSION"));
        let base_labels = format!("{},{}", service_labels, version_labels);

        // === äº‹ä»¶å¤„ç†æŒ‡æ ‡ ===
        output.push_str("# HELP events_processed_total Total number of events processed successfully\n");
        output.push_str("# TYPE events_processed_total counter\n");
        output.push_str(&format!(
            "events_processed_total{{{}}} {}\n",
            base_labels, stats.events_processed
        ));

        output.push_str("# HELP events_failed_total Total number of events that failed processing\n");
        output.push_str("# TYPE events_failed_total counter\n");
        output.push_str(&format!(
            "events_failed_total{{{}}} {}\n",
            base_labels, stats.events_failed
        ));

        output.push_str("# HELP events_success_rate Success rate of event processing (0-1)\n");
        output.push_str("# TYPE events_success_rate gauge\n");
        output.push_str(&format!(
            "events_success_rate{{{}}} {:.4}\n",
            base_labels, stats.success_rate
        ));

        output.push_str("# HELP events_per_second Current events processing rate\n");
        output.push_str("# TYPE events_per_second gauge\n");
        output.push_str(&format!(
            "events_per_second{{{}}} {:.2}\n",
            base_labels, report.events_per_second
        ));

        // === WebSocket æŒ‡æ ‡ ===
        output.push_str("# HELP websocket_connections_total Total number of WebSocket connections established\n");
        output.push_str("# TYPE websocket_connections_total counter\n");
        output.push_str(&format!(
            "websocket_connections_total{{{}}} {}\n",
            base_labels, stats.websocket_connections
        ));

        output.push_str("# HELP websocket_reconnections_total Total number of WebSocket reconnections\n");
        output.push_str("# TYPE websocket_reconnections_total counter\n");
        output.push_str(&format!(
            "websocket_reconnections_total{{{}}} {}\n",
            base_labels, stats.websocket_reconnections
        ));

        output
            .push_str("# HELP websocket_connected Current WebSocket connection status (1=connected, 0=disconnected)\n");
        output.push_str("# TYPE websocket_connected gauge\n");
        output.push_str(&format!(
            "websocket_connected{{{}}} {}\n",
            base_labels,
            if report.websocket_health.is_connected { 1 } else { 0 }
        ));

        output.push_str("# HELP websocket_latency_ms Average WebSocket latency in milliseconds\n");
        output.push_str("# TYPE websocket_latency_ms gauge\n");
        output.push_str(&format!(
            "websocket_latency_ms{{{}}} {:.2}\n",
            base_labels, report.websocket_health.avg_latency_ms
        ));

        // === æ‰¹é‡å†™å…¥æŒ‡æ ‡ ===
        output.push_str("# HELP batch_writes_total Total number of batch writes executed\n");
        output.push_str("# TYPE batch_writes_total counter\n");
        output.push_str(&format!(
            "batch_writes_total{{{}}} {}\n",
            base_labels, stats.batch_writes
        ));

        output.push_str("# HELP batch_writes_per_minute Current batch writes per minute rate\n");
        output.push_str("# TYPE batch_writes_per_minute gauge\n");
        output.push_str(&format!(
            "batch_writes_per_minute{{{}}} {:.2}\n",
            base_labels, report.batches_per_minute
        ));

        output.push_str("# HELP batch_write_duration_ms Average batch write duration in milliseconds\n");
        output.push_str("# TYPE batch_write_duration_ms gauge\n");
        output.push_str(&format!(
            "batch_write_duration_ms{{{}}} {:.2}\n",
            base_labels, report.database_health.avg_write_duration_ms
        ));

        // === æ£€æŸ¥ç‚¹æŒ‡æ ‡ ===
        output.push_str("# HELP checkpoint_saves_total Total number of checkpoint saves\n");
        output.push_str("# TYPE checkpoint_saves_total counter\n");
        output.push_str(&format!(
            "checkpoint_saves_total{{{}}} {}\n",
            base_labels, stats.checkpoint_saves
        ));

        // === æ€§èƒ½æŒ‡æ ‡ ===
        output.push_str("# HELP processing_duration_ms Average event processing duration in milliseconds\n");
        output.push_str("# TYPE processing_duration_ms gauge\n");
        output.push_str(&format!(
            "processing_duration_ms{{{}}} {:.2}\n",
            base_labels, stats.avg_processing_duration_ms
        ));

        output.push_str("# HELP processing_duration_total_ms Total processing time across all events\n");
        output.push_str("# TYPE processing_duration_total_ms gauge\n");
        output.push_str(&format!(
            "processing_duration_total_ms{{{}}} {:.2}\n",
            base_labels, report.avg_processing_time_ms
        ));

        output.push_str("# HELP error_rate Current error rate (0-1)\n");
        output.push_str("# TYPE error_rate gauge\n");
        output.push_str(&format!("error_rate{{{}}} {:.4}\n", base_labels, report.error_rate));

        // === ç³»ç»Ÿèµ„æºæŒ‡æ ‡ ===
        output.push_str("# HELP system_memory_usage_mb Current memory usage in megabytes\n");
        output.push_str("# TYPE system_memory_usage_mb gauge\n");
        output.push_str(&format!(
            "system_memory_usage_mb{{{}}} {:.2}\n",
            base_labels, report.system_resources.memory_usage_mb
        ));

        output.push_str("# HELP system_cpu_usage_percent Current CPU usage percentage\n");
        output.push_str("# TYPE system_cpu_usage_percent gauge\n");
        output.push_str(&format!(
            "system_cpu_usage_percent{{{}}} {:.2}\n",
            base_labels, report.system_resources.cpu_usage_percent
        ));

        // === è¿è¡Œæ—¶æŒ‡æ ‡ ===
        output.push_str("# HELP uptime_seconds Total uptime in seconds\n");
        output.push_str("# TYPE uptime_seconds counter\n");
        output.push_str(&format!("uptime_seconds{{{}}} {}\n", base_labels, stats.uptime_seconds));

        output.push_str("# HELP running_status Current running status (1=running, 0=stopped)\n");
        output.push_str("# TYPE running_status gauge\n");
        output.push_str(&format!(
            "running_status{{{}}} {}\n",
            base_labels,
            if stats.is_running { 1 } else { 0 }
        ));

        // === è‡ªå®šä¹‰æŒ‡æ ‡ ===
        output.push_str("# HELP custom_metrics_count Number of custom metrics registered\n");
        output.push_str("# TYPE custom_metrics_count gauge\n");
        output.push_str(&format!(
            "custom_metrics_count{{{}}} {}\n",
            base_labels, stats.custom_metrics_count
        ));

        // å¯¼å‡ºè‡ªå®šä¹‰æŒ‡æ ‡
        let custom_metrics = self.custom_metrics.read().await;
        for (name, metric) in custom_metrics.iter() {
            // æ ¹æ®æŒ‡æ ‡ç±»å‹å†³å®šPrometheusç±»å‹
            let prom_type = match metric.metric_type {
                MetricType::Counter => "counter",
                MetricType::Gauge => "gauge",
                MetricType::Histogram => "histogram",
                MetricType::Summary => "summary",
            };

            output.push_str(&format!("# HELP {} {}\n", name, metric.description));
            output.push_str(&format!("# TYPE {} {}\n", name, prom_type));

            // æ„å»ºæ ‡ç­¾å­—ç¬¦ä¸²
            let mut labels_vec = vec![service_labels.to_string(), version_labels.clone()];
            for (key, value) in &metric.labels {
                labels_vec.push(format!("{}=\"{}\"", key, value));
            }
            let labels_str = labels_vec.join(",");

            output.push_str(&format!("{}{{{}}} {}\n", name, labels_str, metric.value));
        }

        Ok(output)
    }

    /// æ£€æŸ¥æŒ‡æ ‡æ”¶é›†å™¨æ˜¯å¦å¥åº·
    pub async fn is_healthy(&self) -> bool {
        *self.is_running.read().await
    }
}

impl Clone for MetricsCollector {
    fn clone(&self) -> Self {
        // æ³¨æ„ï¼šå¯¹äºç³»ç»Ÿç›‘æ§ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªæ–°çš„å®ä¾‹
        let mut system = System::new_all();
        system.refresh_all();

        Self {
            config: Arc::clone(&self.config),
            is_running: Arc::clone(&self.is_running),
            events_processed: Arc::clone(&self.events_processed),
            events_failed: Arc::clone(&self.events_failed),
            websocket_connections: Arc::clone(&self.websocket_connections),
            websocket_reconnections: Arc::clone(&self.websocket_reconnections),
            batch_writes: Arc::clone(&self.batch_writes),
            checkpoint_saves: Arc::clone(&self.checkpoint_saves),
            processing_durations: Arc::clone(&self.processing_durations),
            websocket_latencies: Arc::clone(&self.websocket_latencies),
            batch_write_durations: Arc::clone(&self.batch_write_durations),
            start_time: self.start_time,
            last_metrics_report: Arc::clone(&self.last_metrics_report),
            system_monitor: Arc::new(RwLock::new(system)),
            custom_metrics: Arc::clone(&self.custom_metrics),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_config() -> EventListenerConfig {
        EventListenerConfig {
            solana: crate::config::settings::SolanaConfig {
                rpc_url: "https://api.devnet.solana.com".to_string(),
                ws_url: "wss://api.devnet.solana.com".to_string(),
                commitment: "confirmed".to_string(),
                program_ids: vec![solana_sdk::pubkey::Pubkey::new_unique()],
                private_key: None,
            },
            database: crate::config::settings::DatabaseConfig {
                uri: "mongodb://localhost:27017".to_string(),
                database_name: "test".to_string(),
                max_connections: 10,
                min_connections: 2,
            },
            listener: crate::config::settings::ListenerConfig {
                batch_size: 100,
                sync_interval_secs: 30,
                max_retries: 3,
                retry_delay_ms: 1000,
                signature_cache_size: 10000,
                checkpoint_save_interval_secs: 60,
                backoff: crate::config::settings::BackoffConfig::default(),
                batch_write: crate::config::settings::BatchWriteConfig::default(),
            },
            monitoring: crate::config::settings::MonitoringConfig {
                metrics_interval_secs: 60,
                enable_performance_monitoring: true,
                health_check_interval_secs: 30,
            },
        }
    }

    #[test]
    fn test_metric_data_creation() {
        let metric = MetricData::new(
            "test_counter".to_string(),
            MetricType::Counter,
            42.0,
            "Test counter metric".to_string(),
        );

        assert_eq!(metric.name, "test_counter");
        assert_eq!(metric.metric_type, MetricType::Counter);
        assert_eq!(metric.value, 42.0);
        assert_eq!(metric.description, "Test counter metric");
        assert!(metric.labels.is_empty());
    }

    #[test]
    fn test_metric_data_with_labels() {
        let mut labels = HashMap::new();
        labels.insert("environment".to_string(), "test".to_string());
        labels.insert("service".to_string(), "event-listener".to_string());

        let metric = MetricData::new(
            "test_gauge".to_string(),
            MetricType::Gauge,
            100.0,
            "Test gauge metric".to_string(),
        )
        .with_labels(labels.clone());

        assert_eq!(metric.labels, labels);
    }

    #[tokio::test]
    async fn test_metrics_collector_creation() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        let stats = collector.get_stats().await.unwrap();
        assert_eq!(stats.events_processed, 0);
        assert_eq!(stats.events_failed, 0);
        assert!(!stats.is_running);
    }

    #[tokio::test]
    async fn test_record_events() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        // è®°å½•ä¸€äº›äº‹ä»¶
        collector.record_event_processed().await.unwrap();
        collector.record_event_processed().await.unwrap();
        collector.record_event_failed().await.unwrap();

        let stats = collector.get_stats().await.unwrap();
        assert_eq!(stats.events_processed, 2);
        assert_eq!(stats.events_failed, 1);
        assert_eq!(stats.success_rate, 2.0 / 3.0);
    }

    #[tokio::test]
    async fn test_record_durations() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        // è®°å½•ä¸€äº›å¤„ç†è€—æ—¶
        collector
            .record_processing_duration(Duration::from_millis(100))
            .await
            .unwrap();
        collector
            .record_processing_duration(Duration::from_millis(200))
            .await
            .unwrap();
        collector
            .record_processing_duration(Duration::from_millis(150))
            .await
            .unwrap();

        let stats = collector.get_stats().await.unwrap();
        assert_eq!(stats.avg_processing_duration_ms, 150.0);
    }

    #[tokio::test]
    async fn test_custom_metrics() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        let metric = MetricData::new(
            "custom_counter".to_string(),
            MetricType::Counter,
            10.0,
            "Custom counter".to_string(),
        );

        collector.add_custom_metric(metric).await.unwrap();

        let stats = collector.get_stats().await.unwrap();
        assert_eq!(stats.custom_metrics_count, 1);

        // æ›´æ–°è‡ªå®šä¹‰æŒ‡æ ‡
        collector.update_custom_metric("custom_counter", 20.0).await.unwrap();
        // è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šéªŒè¯é€»è¾‘
    }

    #[tokio::test]
    async fn test_reset_metrics() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        // è®°å½•ä¸€äº›æ•°æ®
        collector.record_event_processed().await.unwrap();
        collector.record_websocket_connection().await.unwrap();

        let stats_before = collector.get_stats().await.unwrap();
        assert_eq!(stats_before.events_processed, 1);
        assert_eq!(stats_before.websocket_connections, 1);

        // é‡ç½®æŒ‡æ ‡
        collector.reset_metrics().await.unwrap();

        let stats_after = collector.get_stats().await.unwrap();
        assert_eq!(stats_after.events_processed, 0);
        assert_eq!(stats_after.websocket_connections, 0);
    }

    #[tokio::test]
    async fn test_system_resource_monitoring() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        // ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šï¼Œåº”è¯¥åŒ…å«çœŸå®çš„ç³»ç»Ÿèµ„æºä¿¡æ¯
        let report = collector.generate_performance_report().await.unwrap();

        // éªŒè¯ç³»ç»Ÿèµ„æºç›‘æ§ä¸å†ä½¿ç”¨å ä½ç¬¦å€¼
        assert!(report.system_resources.memory_usage_mb >= 0.0);
        assert!(report.system_resources.cpu_usage_percent >= 0.0);
        assert!(
            report.system_resources.cpu_usage_percent
                <= 100.0 * std::thread::available_parallelism().unwrap().get() as f64
        );

        println!(
            "âœ… ç³»ç»Ÿèµ„æºç›‘æ§: å†…å­˜ {:.2}MB, CPU {:.2}%",
            report.system_resources.memory_usage_mb, report.system_resources.cpu_usage_percent
        );
    }

    #[tokio::test]
    async fn test_generate_performance_report() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        // è®°å½•ä¸€äº›æ•°æ®
        collector.record_event_processed().await.unwrap();
        collector
            .record_processing_duration(Duration::from_millis(500))
            .await
            .unwrap();
        collector.record_batch_write().await.unwrap();

        let report = collector.generate_performance_report().await.unwrap();

        assert_eq!(report.websocket_health.connections_count, 0);
        assert_eq!(report.database_health.batch_writes_count, 1);
        assert!(report.uptime_seconds < 60); // åº”è¯¥å°äº60ç§’
    }

    #[tokio::test]
    async fn test_export_prometheus_metrics_enhanced() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        // è®°å½•ä¸€äº›æ•°æ®æ¥æµ‹è¯•å¢å¼ºåŠŸèƒ½
        collector.record_event_processed().await.unwrap();
        collector.record_event_failed().await.unwrap();
        collector.record_websocket_connection().await.unwrap();
        collector.record_batch_write().await.unwrap();

        // æ·»åŠ ä¸€ä¸ªè‡ªå®šä¹‰æŒ‡æ ‡
        let custom_metric = MetricData::new(
            "test_custom_metric".to_string(),
            MetricType::Gauge,
            42.5,
            "Test custom metric for enhanced export".to_string(),
        )
        .with_label("environment".to_string(), "test".to_string());

        collector.add_custom_metric(custom_metric).await.unwrap();

        let prometheus_output = collector.export_prometheus_metrics().await.unwrap();

        // è·å–å½“å‰ç‰ˆæœ¬ç”¨äºæµ‹è¯•
        let current_version = env!("CARGO_PKG_VERSION");
        let expected_label_pattern = format!("service=\"event-listener\",version=\"{}\"", current_version);

        // éªŒè¯åŸºç¡€æŒ‡æ ‡
        assert!(prometheus_output.contains(&format!("events_processed_total{{{}}} 1", expected_label_pattern)));
        assert!(prometheus_output.contains(&format!("events_failed_total{{{}}} 1", expected_label_pattern)));

        // éªŒè¯å¢å¼ºåŠŸèƒ½
        assert!(prometheus_output.contains("events_success_rate"));
        assert!(prometheus_output.contains("events_per_second"));
        assert!(prometheus_output.contains("websocket_connected"));
        assert!(prometheus_output.contains("system_memory_usage_mb"));
        assert!(prometheus_output.contains("system_cpu_usage_percent"));
        assert!(prometheus_output.contains("uptime_seconds"));
        assert!(prometheus_output.contains("running_status"));

        // éªŒè¯è‡ªå®šä¹‰æŒ‡æ ‡
        assert!(prometheus_output.contains("test_custom_metric"));
        assert!(prometheus_output.contains("Test custom metric for enhanced export"));
        assert!(prometheus_output.contains("environment=\"test\""));
        assert!(prometheus_output.contains("42.5"));

        // éªŒè¯Prometheusæ ¼å¼æ­£ç¡®æ€§
        assert!(prometheus_output.contains("# HELP"));
        assert!(prometheus_output.contains("# TYPE"));

        // éªŒè¯æ‰€æœ‰æ ‡ç­¾éƒ½åŒ…å«serviceå’Œversion
        let lines: Vec<&str> = prometheus_output.lines().collect();
        for line in lines.iter().filter(|line| !line.starts_with('#') && !line.is_empty()) {
            if line.contains('{') {
                assert!(
                    line.contains("service=\"event-listener\""),
                    "Line missing service label: {}",
                    line
                );
                assert!(
                    line.contains(&format!("version=\"{}\"", current_version)),
                    "Line missing version label: {}",
                    line
                );
            }
        }

        println!("âœ… å¢å¼ºçš„Prometheuså¯¼å‡ºåŒ…å« {} è¡ŒæŒ‡æ ‡", lines.len());
    }

    #[tokio::test]
    async fn test_is_healthy() {
        let config = create_test_config();
        let collector = MetricsCollector::new(&config).unwrap();

        // åˆå§‹çŠ¶æ€ä¸å¥åº·ï¼ˆæœªè¿è¡Œï¼‰
        assert!(!collector.is_healthy().await);

        // æ¨¡æ‹Ÿè¿è¡ŒçŠ¶æ€
        {
            let mut is_running = collector.is_running.write().await;
            *is_running = true;
        }

        // è¿è¡ŒçŠ¶æ€ä¸‹åº”è¯¥å¥åº·
        assert!(collector.is_healthy().await);
    }
}
