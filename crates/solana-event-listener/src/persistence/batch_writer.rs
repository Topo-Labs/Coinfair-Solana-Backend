use crate::{
    config::EventListenerConfig,
    error::{EventListenerError, Result},
    parser::ParsedEvent,
    persistence::EventStorage,
};
use std::{
    collections::{HashMap, VecDeque},
    sync::{
        atomic::{AtomicBool, AtomicU64, Ordering},
        Arc,
    },
    time::{Duration, Instant},
};
use tokio::{
    sync::{mpsc, Mutex, RwLock},
    time::{interval, timeout},
};
use tracing::{debug, error, info, warn};
use uuid::Uuid;

/// æ‰¹é‡å†™å…¥å™¨
///
/// è´Ÿè´£:
/// - æ”¶é›†äº‹ä»¶åˆ°æ‰¹é‡ç¼“å†²åŒº
/// - å®šæœŸæˆ–è¾¾åˆ°é˜ˆå€¼æ—¶æ‰¹é‡å†™å…¥æ•°æ®åº“
/// - æä¾›å†™å…¥æ€§èƒ½ç›‘æ§
/// - å¤„ç†å†™å…¥å¤±è´¥å’Œé‡è¯•
pub struct BatchWriter {
    config: Arc<EventListenerConfig>,
    event_storage: Arc<EventStorage>,

    // æ‰¹é‡å†™å…¥é…ç½®
    batch_size: usize,
    max_wait_duration: Duration,
    buffer_size: usize,

    // è¿è¡ŒçŠ¶æ€
    is_running: Arc<AtomicBool>,

    // äº‹ä»¶ç¼“å†²åŒº
    event_buffer: Arc<Mutex<VecDeque<ParsedEvent>>>,

    // ç»Ÿè®¡ä¿¡æ¯
    events_queued: Arc<AtomicU64>,
    events_written: Arc<AtomicU64>,
    events_failed: Arc<AtomicU64>,
    batches_written: Arc<AtomicU64>,
    last_write_time: Arc<RwLock<Option<Instant>>>,

    // äº‹ä»¶æäº¤é€šé“
    event_sender: mpsc::UnboundedSender<ParsedEvent>,
    event_receiver: Arc<Mutex<mpsc::UnboundedReceiver<ParsedEvent>>>,

    // é‡è¯•ç®¡ç† (æµ‹è¯•å¯è§)
    #[cfg(test)]
    pub retry_counts: Arc<Mutex<HashMap<String, u32>>>, // æ‰¹æ¬¡ID -> é‡è¯•æ¬¡æ•°
    #[cfg(not(test))]
    retry_counts: Arc<Mutex<HashMap<String, u32>>>, // æ‰¹æ¬¡ID -> é‡è¯•æ¬¡æ•°
    #[cfg(test)]
    pub max_retries: u32,
    #[cfg(not(test))]
    max_retries: u32,
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct BatchWriterStats {
    pub is_running: bool,
    pub events_queued: u64,
    pub events_written: u64,
    pub events_failed: u64,
    pub batches_written: u64,
    pub buffer_size: usize,
    #[serde(skip)]
    pub last_write_time: Option<Instant>,
    pub success_rate: f64,
    pub average_batch_size: f64,
}

impl BatchWriter {
    /// åˆ›å»ºæ–°çš„æ‰¹é‡å†™å…¥å™¨
    pub async fn new(config: &EventListenerConfig) -> Result<Self> {
        let config = Arc::new(config.clone());
        let event_storage = Arc::new(EventStorage::new(&config).await?);

        let batch_size = config.listener.batch_write.batch_size;
        let max_wait_duration = Duration::from_millis(config.listener.batch_write.max_wait_ms);
        let buffer_size = config.listener.batch_write.buffer_size;

        let (event_sender, event_receiver) = mpsc::unbounded_channel::<ParsedEvent>();
        let event_receiver = Arc::new(Mutex::new(event_receiver));

        info!(
            "ğŸ”§ åˆå§‹åŒ–æ‰¹é‡å†™å…¥å™¨ï¼Œbatch_size: {}, max_wait: {:?}, buffer_size: {}",
            batch_size, max_wait_duration, buffer_size
        );

        let max_retries = config.listener.max_retries;

        Ok(Self {
            config,
            event_storage,
            batch_size,
            max_wait_duration,
            buffer_size,
            is_running: Arc::new(AtomicBool::new(false)),
            event_buffer: Arc::new(Mutex::new(VecDeque::with_capacity(buffer_size))),
            events_queued: Arc::new(AtomicU64::new(0)),
            events_written: Arc::new(AtomicU64::new(0)),
            events_failed: Arc::new(AtomicU64::new(0)),
            batches_written: Arc::new(AtomicU64::new(0)),
            last_write_time: Arc::new(RwLock::new(None)),
            event_sender,
            event_receiver,
            retry_counts: Arc::new(Mutex::new(HashMap::new())),
            max_retries,
        })
    }

    /// å¯åŠ¨æ‰¹é‡å¤„ç†
    pub async fn start_batch_processing(&self) -> Result<()> {
        if self.is_running.load(Ordering::Relaxed) {
            warn!("æ‰¹é‡å†™å…¥å™¨å·²åœ¨è¿è¡Œä¸­");
            return Ok(());
        }

        self.is_running.store(true, Ordering::Relaxed);
        info!("ğŸš€ å¯åŠ¨æ‰¹é‡å†™å…¥å¤„ç†");

        // å¯åŠ¨äº‹ä»¶æ”¶é›†ä»»åŠ¡
        let collection_task = {
            let writer = self.clone();
            tokio::spawn(async move {
                writer.event_collection_loop().await;
            })
        };

        // å¯åŠ¨æ‰¹é‡å†™å…¥ä»»åŠ¡
        let batch_write_task = {
            let writer = self.clone();
            tokio::spawn(async move {
                writer.batch_write_loop().await;
            })
        };

        // ç­‰å¾…ä»»åŠ¡å®Œæˆ
        tokio::select! {
            _ = collection_task => {
                warn!("äº‹ä»¶æ”¶é›†ä»»åŠ¡å®Œæˆ");
            }
            _ = batch_write_task => {
                warn!("æ‰¹é‡å†™å…¥ä»»åŠ¡å®Œæˆ");
            }
        }

        Ok(())
    }

    /// åœæ­¢æ‰¹é‡å¤„ç†å¹¶åˆ·æ–°ç¼“å†²åŒº
    pub async fn stop(&self) -> Result<()> {
        info!("ğŸ›‘ åœæ­¢æ‰¹é‡å†™å…¥å™¨");
        self.is_running.store(false, Ordering::Relaxed);

        // åˆ·æ–°å‰©ä½™çš„äº‹ä»¶
        self.flush().await?;

        Ok(())
    }

    /// æäº¤äº‹ä»¶åˆ°æ‰¹é‡å†™å…¥é˜Ÿåˆ—
    pub async fn submit_event(&self, event: ParsedEvent) -> Result<()> {
        if !self.is_running.load(Ordering::Relaxed) {
            return Err(EventListenerError::Persistence("æ‰¹é‡å†™å…¥å™¨æœªè¿è¡Œ".to_string()));
        }

        self.event_sender
            .send(event)
            .map_err(|_| EventListenerError::Persistence("äº‹ä»¶æäº¤å¤±è´¥ï¼šé€šé“å·²å…³é—­".to_string()))?;

        self.events_queued.fetch_add(1, Ordering::Relaxed);
        Ok(())
    }

    /// æ‰¹é‡æäº¤å¤šä¸ªäº‹ä»¶åˆ°å†™å…¥é˜Ÿåˆ—
    ///
    /// è¿™ä¸ªæ–¹æ³•æ¯”å¤šæ¬¡è°ƒç”¨ submit_event æ›´é«˜æ•ˆï¼Œå› ä¸ºå®ƒå‡å°‘äº†é€šé“æ“ä½œçš„å¼€é”€
    ///
    /// # å‚æ•°
    /// * `events` - è¦æäº¤çš„äº‹ä»¶å‘é‡
    ///
    /// # è¿”å›å€¼
    /// å¦‚æœæ‰€æœ‰äº‹ä»¶éƒ½æˆåŠŸæäº¤åˆ™è¿”å› Ok(())ï¼Œå¦åˆ™è¿”å›ç¬¬ä¸€ä¸ªé‡åˆ°çš„é”™è¯¯
    ///
    /// # æ³¨æ„
    /// å¦‚æœåœ¨æäº¤è¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯ï¼Œå·²æäº¤çš„äº‹ä»¶ä¸ä¼šå›æ»š
    pub async fn submit_events(&self, events: Vec<ParsedEvent>) -> Result<()> {
        if events.is_empty() {
            return Ok(());
        }

        if !self.is_running.load(Ordering::Relaxed) {
            return Err(EventListenerError::Persistence("æ‰¹é‡å†™å…¥å™¨æœªè¿è¡Œ".to_string()));
        }

        let event_count = events.len();

        // æ‰¹é‡å‘é€æ‰€æœ‰äº‹ä»¶
        for event in events {
            self.event_sender
                .send(event)
                .map_err(|_| EventListenerError::Persistence("æ‰¹é‡äº‹ä»¶æäº¤å¤±è´¥ï¼šé€šé“å·²å…³é—­".to_string()))?;
        }

        // æ›´æ–°ç»Ÿè®¡è®¡æ•°å™¨
        self.events_queued.fetch_add(event_count as u64, Ordering::Relaxed);

        debug!("ğŸ“¦ æ‰¹é‡æäº¤{}ä¸ªäº‹ä»¶åˆ°å†™å…¥é˜Ÿåˆ—", event_count);
        Ok(())
    }

    /// äº‹ä»¶æ”¶é›†å¾ªç¯
    async fn event_collection_loop(&self) {
        info!("ğŸ“¥ å¯åŠ¨äº‹ä»¶æ”¶é›†å¾ªç¯");

        let mut receiver = self.event_receiver.lock().await;

        while self.is_running.load(Ordering::Relaxed) {
            match timeout(Duration::from_millis(100), receiver.recv()).await {
                Ok(Some(event)) => {
                    // å°†äº‹ä»¶æ·»åŠ åˆ°ç¼“å†²åŒº
                    {
                        let mut buffer = self.event_buffer.lock().await;

                        // æ£€æŸ¥ç¼“å†²åŒºå®¹é‡
                        if buffer.len() >= self.buffer_size {
                            warn!("âš ï¸ äº‹ä»¶ç¼“å†²åŒºå·²æ»¡ï¼Œä¸¢å¼ƒæœ€æ—§çš„äº‹ä»¶");
                            buffer.pop_front();
                        }

                        buffer.push_back(event);
                    }

                    debug!("ğŸ“¦ äº‹ä»¶å·²æ·»åŠ åˆ°ç¼“å†²åŒº");
                }
                Ok(None) => {
                    warn!("äº‹ä»¶æ¥æ”¶é€šé“å·²å…³é—­");
                    break;
                }
                Err(_) => {
                    // è¶…æ—¶ï¼Œç»§ç»­å¾ªç¯
                    continue;
                }
            }
        }

        info!("ğŸ“¥ äº‹ä»¶æ”¶é›†å¾ªç¯å·²åœæ­¢");
    }

    /// æ‰¹é‡å†™å…¥å¾ªç¯
    async fn batch_write_loop(&self) {
        info!("ğŸ’¾ å¯åŠ¨æ‰¹é‡å†™å…¥å¾ªç¯");
        info!(
            "ğŸ“Š æ‰¹é‡é…ç½® - batch_size: {}, max_wait: {:?}",
            self.batch_size, self.max_wait_duration
        );

        // ä½¿ç”¨è¾ƒçŸ­çš„æ£€æŸ¥é—´éš”ï¼Œä½†åŸºäºæ—¶é—´çª—å£å†³å®šæ˜¯å¦å†™å…¥
        let check_interval = Duration::from_millis(std::cmp::min(1000, self.max_wait_duration.as_millis() as u64));
        let mut write_interval = interval(check_interval);

        // è®°å½•ä¸Šæ¬¡å†™å…¥æ—¶é—´ï¼Œç”¨äºæ—¶é—´çª—å£åˆ¤æ–­
        let mut last_write_time = Instant::now();

        while self.is_running.load(Ordering::Relaxed) {
            write_interval.tick().await;

            // æ£€æŸ¥æ˜¯å¦éœ€è¦å†™å…¥
            let buffer_size = {
                let buffer = self.event_buffer.lock().await;
                buffer.len()
            };

            if buffer_size == 0 {
                continue;
            }

            let time_since_last_write = last_write_time.elapsed();

            // æ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶å°±è§¦å‘æ‰¹é‡å†™å…¥ï¼š
            // 1. ç¼“å†²åŒºè¾¾åˆ°æ‰¹é‡å¤§å°é˜ˆå€¼
            // 2. æœ‰äº‹ä»¶ä¸”ç­‰å¾…æ—¶é—´è¶…è¿‡æœ€å¤§ç­‰å¾…æ—¶é—´
            let should_write = buffer_size >= self.batch_size || time_since_last_write >= self.max_wait_duration;

            if should_write {
                debug!(
                    "ğŸ” è§¦å‘æ‰¹é‡å†™å…¥ - ç¼“å†²åŒº: {}/{}, ç­‰å¾…æ—¶é—´: {:?}/{:?}",
                    buffer_size, self.batch_size, time_since_last_write, self.max_wait_duration
                );

                if let Err(e) = self.write_batch().await {
                    error!("âŒ æ‰¹é‡å†™å…¥å¤±è´¥: {}", e);
                } else {
                    // æˆåŠŸå†™å…¥åé‡ç½®æ—¶é—´
                    last_write_time = Instant::now();
                }
            }
        }

        info!("ğŸ’¾ æ‰¹é‡å†™å…¥å¾ªç¯å·²åœæ­¢");
    }

    /// æ‰§è¡Œæ‰¹é‡å†™å…¥
    async fn write_batch(&self) -> Result<()> {
        let batch = {
            let mut buffer = self.event_buffer.lock().await;
            if buffer.is_empty() {
                return Ok(());
            }

            // æå–æ‰¹é‡äº‹ä»¶
            let batch_size = std::cmp::min(self.batch_size, buffer.len());
            let mut batch = Vec::with_capacity(batch_size);

            for _ in 0..batch_size {
                if let Some(event) = buffer.pop_front() {
                    batch.push(event);
                }
            }

            batch
        };

        if batch.is_empty() {
            return Ok(());
        }

        let batch_size = batch.len();
        info!("ğŸ“¦ æ‰¹é‡å†™å…¥å¼€å§‹ - äº‹ä»¶æ•°é‡: {}", batch_size);

        let start_time = Instant::now();

        // æ‰§è¡Œæ‰¹é‡å†™å…¥
        match self.event_storage.write_batch(&batch).await {
            Ok(written_count) => {
                let duration = start_time.elapsed();

                // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.events_written.fetch_add(written_count, Ordering::Relaxed);
                self.batches_written.fetch_add(1, Ordering::Relaxed);
                {
                    let mut last_write = self.last_write_time.write().await;
                    *last_write = Some(Instant::now());
                }

                info!(
                    "âœ… æ‰¹é‡å†™å…¥å®Œæˆï¼Œå†™å…¥: {}/{} äº‹ä»¶ï¼Œè€—æ—¶: {:?}",
                    written_count, batch_size, duration
                );
            }
            Err(e) => {
                // æ›´æ–°å¤±è´¥ç»Ÿè®¡
                self.events_failed.fetch_add(batch_size as u64, Ordering::Relaxed);

                error!("âŒ æ‰¹é‡å†™å…¥å¤±è´¥: {}", e);

                // ç”Ÿæˆæ‰¹æ¬¡IDç”¨äºé‡è¯•è·Ÿè¸ª
                let batch_id = Uuid::new_v4().to_string();

                // å°†å¤±è´¥çš„äº‹ä»¶é‡æ–°åŠ å…¥ç¼“å†²åŒºï¼ˆå¯é€‰æ‹©æ€§é‡è¯•ï¼‰
                if self.should_retry_batch_internal(&batch, &e, &batch_id).await {
                    // æ·»åŠ æŒ‡æ•°é€€é¿å»¶è¿Ÿ
                    let retry_counts = self.retry_counts.lock().await;
                    let current_retries = retry_counts.get(&batch_id).copied().unwrap_or(0);
                    drop(retry_counts);

                    let delay_ms = self.config.listener.retry_delay_ms * (2_u64.pow(current_retries));
                    let delay = std::cmp::min(delay_ms, 30000); // æœ€å¤§å»¶è¿Ÿ30ç§’

                    tokio::time::sleep(Duration::from_millis(delay)).await;

                    self.requeue_batch(batch).await;
                } else {
                    warn!("ğŸš« æ‰¹æ¬¡é‡è¯•å·²æ”¾å¼ƒï¼Œä¸¢å¼ƒ {} ä¸ªäº‹ä»¶", batch.len());
                }

                return Err(e);
            }
        }

        Ok(())
    }

    /// åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•æ‰¹é‡å†™å…¥
    async fn should_retry_batch_internal(
        &self,
        batch: &[ParsedEvent],
        error: &EventListenerError,
        batch_id: &str,
    ) -> bool {
        // æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦é‡è¯•
        let is_retryable_error = match error {
            EventListenerError::Database(_) => true,            // æ•°æ®åº“è¿æ¥é—®é¢˜å¯é‡è¯•
            EventListenerError::IO(_) => true,                  // IOé”™è¯¯å¯é‡è¯•
            EventListenerError::WebSocket(_) => true,           // WebSocketè¿æ¥é—®é¢˜å¯é‡è¯•
            EventListenerError::SolanaRpc(_) => true,           // Solana RPCé”™è¯¯å¯é‡è¯•
            EventListenerError::Network(_) => true,             // ç½‘ç»œé”™è¯¯å¯é‡è¯•
            EventListenerError::Persistence(_) => true,         // æŒä¹…åŒ–é”™è¯¯å¯é‡è¯•
            EventListenerError::EventParsing(_) => false,       // è§£æé”™è¯¯ä¸é‡è¯•
            EventListenerError::DiscriminatorMismatch => false, // Discriminatorä¸åŒ¹é…ä¸é‡è¯•
            EventListenerError::Config(_) => false,             // é…ç½®é”™è¯¯ä¸é‡è¯•
            EventListenerError::Checkpoint(_) => false,         // æ£€æŸ¥ç‚¹é”™è¯¯ä¸é‡è¯•
            EventListenerError::Metrics(_) => false,            // æŒ‡æ ‡é”™è¯¯ä¸é‡è¯•
            EventListenerError::Serialization(_) => false,      // åºåˆ—åŒ–é”™è¯¯ä¸é‡è¯•
            EventListenerError::Base64Decode(_) => false,       // Base64è§£ç é”™è¯¯ä¸é‡è¯•
            EventListenerError::SolanaSDK(_) => false,          // Solana SDKé”™è¯¯ä¸é‡è¯•
            EventListenerError::Unknown(_) => false,            // æœªçŸ¥é”™è¯¯ä¸é‡è¯•
        };

        if !is_retryable_error {
            debug!("âŒ é”™è¯¯ç±»å‹ä¸å¯é‡è¯•: {}", error);
            return false;
        }

        // æ£€æŸ¥é‡è¯•æ¬¡æ•°
        let mut retry_counts = self.retry_counts.lock().await;
        let current_retries = retry_counts.get(batch_id).copied().unwrap_or(0);

        if current_retries >= self.max_retries {
            warn!("âš ï¸ æ‰¹æ¬¡ {} å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {}", batch_id, self.max_retries);
            retry_counts.remove(batch_id);
            return false;
        }

        // å¢åŠ é‡è¯•è®¡æ•°
        retry_counts.insert(batch_id.to_string(), current_retries + 1);

        info!(
            "ğŸ”„ æ‰¹æ¬¡ {} å°†è¿›è¡Œç¬¬ {} æ¬¡é‡è¯•ï¼ˆæ‰¹æ¬¡å¤§å°: {}ï¼‰",
            batch_id,
            current_retries + 1,
            batch.len()
        );

        true
    }

    /// åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•æ‰¹é‡å†™å…¥ (æµ‹è¯•å¯è§)
    #[cfg(test)]
    pub async fn should_retry_batch(&self, batch: &[ParsedEvent], error: &EventListenerError, batch_id: &str) -> bool {
        // è°ƒç”¨å†…éƒ¨æ–¹æ³•
        self.should_retry_batch_internal(batch, error, batch_id).await
    }

    /// å°†æ‰¹é‡äº‹ä»¶é‡æ–°åŠ å…¥é˜Ÿåˆ—
    async fn requeue_batch(&self, batch: Vec<ParsedEvent>) {
        warn!("ğŸ”„ é‡æ–°æ’é˜Ÿ {} ä¸ªå¤±è´¥çš„äº‹ä»¶", batch.len());

        let mut buffer = self.event_buffer.lock().await;

        // å°†å¤±è´¥çš„äº‹ä»¶æ·»åŠ åˆ°ç¼“å†²åŒºå‰éƒ¨ï¼ˆä¼˜å…ˆå¤„ç†ï¼‰
        for event in batch.into_iter().rev() {
            if buffer.len() >= self.buffer_size {
                // å¦‚æœç¼“å†²åŒºæ»¡äº†ï¼Œä¸¢å¼ƒæœ€æ—§çš„äº‹ä»¶
                buffer.pop_back();
            }
            buffer.push_front(event);
        }
    }

    /// åˆ·æ–°æ‰€æœ‰ç¼“å†²åŒºä¸­çš„äº‹ä»¶
    pub async fn flush(&self) -> Result<()> {
        info!("ğŸš¿ åˆ·æ–°æ‰¹é‡å†™å…¥ç¼“å†²åŒº");

        let mut attempts = 0;
        const MAX_ATTEMPTS: u32 = 3;

        while attempts < MAX_ATTEMPTS {
            let buffer_size = {
                let buffer = self.event_buffer.lock().await;
                buffer.len()
            };

            if buffer_size == 0 {
                info!("âœ… ç¼“å†²åŒºå·²æ¸…ç©º");
                break;
            }

            info!(
                "ğŸ’¾ åˆ·æ–°å‰©ä½™ {} ä¸ªäº‹ä»¶ (å°è¯• {}/{})",
                buffer_size,
                attempts + 1,
                MAX_ATTEMPTS
            );

            match self.write_batch().await {
                Ok(()) => {
                    info!("âœ… åˆ·æ–°æ‰¹é‡å†™å…¥æˆåŠŸ");
                }
                Err(e) => {
                    error!("âŒ åˆ·æ–°æ‰¹é‡å†™å…¥å¤±è´¥: {}", e);
                    attempts += 1;

                    if attempts >= MAX_ATTEMPTS {
                        return Err(e);
                    }

                    // ç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
                    tokio::time::sleep(Duration::from_millis(1000)).await;
                }
            }
        }

        Ok(())
    }

    /// æ£€æŸ¥æ‰¹é‡å†™å…¥å™¨æ˜¯å¦å¥åº·
    pub async fn is_healthy(&self) -> bool {
        let is_running = self.is_running.load(Ordering::Relaxed);
        let buffer_size = {
            let buffer = self.event_buffer.lock().await;
            buffer.len()
        };

        // æ£€æŸ¥æ˜¯å¦è¿è¡Œæ­£å¸¸ä¸”ç¼“å†²åŒºæœªè¿‡è½½
        is_running && buffer_size < self.buffer_size
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_stats(&self) -> BatchWriterStats {
        let events_written = self.events_written.load(Ordering::Relaxed);
        let events_failed = self.events_failed.load(Ordering::Relaxed);
        let batches_written = self.batches_written.load(Ordering::Relaxed);
        let total_events = events_written + events_failed;

        let success_rate = if total_events > 0 {
            events_written as f64 / total_events as f64
        } else {
            1.0
        };

        let average_batch_size = if batches_written > 0 {
            events_written as f64 / batches_written as f64
        } else {
            0.0
        };

        let buffer_size = {
            let buffer = self.event_buffer.lock().await;
            buffer.len()
        };

        BatchWriterStats {
            is_running: self.is_running.load(Ordering::Relaxed),
            events_queued: self.events_queued.load(Ordering::Relaxed),
            events_written,
            events_failed,
            batches_written,
            buffer_size,
            last_write_time: *self.last_write_time.read().await,
            success_rate,
            average_batch_size,
        }
    }

    /// é‡ç½®ç»Ÿè®¡ä¿¡æ¯
    pub async fn reset_stats(&self) {
        self.events_queued.store(0, Ordering::Relaxed);
        self.events_written.store(0, Ordering::Relaxed);
        self.events_failed.store(0, Ordering::Relaxed);
        self.batches_written.store(0, Ordering::Relaxed);
        {
            let mut last_write = self.last_write_time.write().await;
            *last_write = None;
        }
        info!("ğŸ“Š æ‰¹é‡å†™å…¥å™¨ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®");
    }
}

impl Clone for BatchWriter {
    fn clone(&self) -> Self {
        Self {
            config: Arc::clone(&self.config),
            event_storage: Arc::clone(&self.event_storage),
            batch_size: self.batch_size,
            max_wait_duration: self.max_wait_duration,
            buffer_size: self.buffer_size,
            is_running: Arc::clone(&self.is_running),
            event_buffer: Arc::clone(&self.event_buffer),
            events_queued: Arc::clone(&self.events_queued),
            events_written: Arc::clone(&self.events_written),
            events_failed: Arc::clone(&self.events_failed),
            batches_written: Arc::clone(&self.batches_written),
            last_write_time: Arc::clone(&self.last_write_time),
            event_sender: self.event_sender.clone(),
            event_receiver: Arc::clone(&self.event_receiver),
            retry_counts: Arc::clone(&self.retry_counts),
            max_retries: self.max_retries,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::{event_parser::TokenCreationEventData, ParsedEvent};
    use solana_sdk::pubkey::Pubkey;

    fn create_test_config() -> EventListenerConfig {
        EventListenerConfig {
            solana: crate::config::settings::SolanaConfig {
                rpc_url: "https://api.devnet.solana.com".to_string(),
                ws_url: "wss://api.devnet.solana.com".to_string(),
                commitment: "confirmed".to_string(),
                program_ids: vec![solana_sdk::pubkey::Pubkey::new_unique()],
                private_key: None,
            },
            database: crate::config::settings::DatabaseConfig {
                uri: "mongodb://localhost:27017".to_string(),
                database_name: "test".to_string(),
                max_connections: 10,
                min_connections: 2,
            },
            listener: crate::config::settings::ListenerConfig {
                batch_size: 100,
                sync_interval_secs: 30,
                max_retries: 3,
                retry_delay_ms: 1000,
                signature_cache_size: 10000,
                checkpoint_save_interval_secs: 60,
                backoff: crate::config::settings::BackoffConfig::default(),
                batch_write: crate::config::settings::BatchWriteConfig {
                    batch_size: 5,
                    max_wait_ms: 1000,
                    buffer_size: 100,
                    concurrent_writers: 2,
                },
            },
            monitoring: crate::config::settings::MonitoringConfig {
                metrics_interval_secs: 60,
                enable_performance_monitoring: true,
                health_check_interval_secs: 30,
            },
        }
    }

    fn create_test_event() -> ParsedEvent {
        ParsedEvent::TokenCreation(TokenCreationEventData {
            mint_address: Pubkey::new_unique().to_string(),
            name: "Test Token".to_string(),
            symbol: "TEST".to_string(),
            uri: "https://example.com/metadata.json".to_string(),
            decimals: 9,
            supply: 1000000,
            creator: Pubkey::new_unique().to_string(),
            has_whitelist: false,
            whitelist_deadline: 0,
            created_at: 1234567890,
            signature: "test_signature".to_string(),
            slot: 12345,
        })
    }

    #[tokio::test]
    async fn test_batch_writer_creation() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        let stats = writer.get_stats().await;
        assert!(!stats.is_running);
        assert_eq!(stats.events_queued, 0);
        assert_eq!(stats.buffer_size, 0);
    }

    #[tokio::test]
    async fn test_submit_event() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        // å¯åŠ¨æ‰¹é‡å†™å…¥å™¨
        writer.is_running.store(true, Ordering::Relaxed);

        let event = create_test_event();
        writer.submit_event(event).await.unwrap();

        let stats = writer.get_stats().await;
        assert_eq!(stats.events_queued, 1);
    }

    #[tokio::test]
    async fn test_submit_events() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        // å¯åŠ¨æ‰¹é‡å†™å…¥å™¨
        writer.is_running.store(true, Ordering::Relaxed);

        // åˆ›å»ºå¤šä¸ªæµ‹è¯•äº‹ä»¶
        let events = vec![create_test_event(), create_test_event(), create_test_event()];
        let event_count = events.len();

        writer.submit_events(events).await.unwrap();

        let stats = writer.get_stats().await;
        assert_eq!(stats.events_queued, event_count as u64);
    }

    #[tokio::test]
    async fn test_submit_empty_events() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        // å¯åŠ¨æ‰¹é‡å†™å…¥å™¨
        writer.is_running.store(true, Ordering::Relaxed);

        // æäº¤ç©ºçš„äº‹ä»¶å‘é‡åº”è¯¥æˆåŠŸä½†ä¸æ”¹å˜ç»Ÿè®¡
        let events: Vec<ParsedEvent> = vec![];
        writer.submit_events(events).await.unwrap();

        let stats = writer.get_stats().await;
        assert_eq!(stats.events_queued, 0);
    }

    #[tokio::test]
    async fn test_retry_logic() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        let test_batch = vec![create_test_event()];
        let batch_id = "test-batch-123";

        // æµ‹è¯•å¯é‡è¯•é”™è¯¯
        let retryable_error = EventListenerError::Persistence("è¿æ¥è¶…æ—¶".to_string());
        assert!(writer.should_retry_batch(&test_batch, &retryable_error, batch_id).await);

        // æµ‹è¯•ä¸å¯é‡è¯•é”™è¯¯
        let non_retryable_error = EventListenerError::EventParsing("è§£æå¤±è´¥".to_string());
        assert!(
            !writer
                .should_retry_batch(&test_batch, &non_retryable_error, batch_id)
                .await
        );

        // æµ‹è¯•é‡è¯•æ¬¡æ•°é™åˆ¶
        let database_error = EventListenerError::Persistence("è¿æ¥å¤±è´¥".to_string());
        let batch_id_limit = "test-batch-limit";

        // ç¬¬ä¸€æ¬¡é‡è¯•åº”è¯¥æˆåŠŸ
        assert!(
            writer
                .should_retry_batch(&test_batch, &database_error, batch_id_limit)
                .await
        );

        // æ¨¡æ‹Ÿè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
        {
            let mut retry_counts = writer.retry_counts.lock().await;
            retry_counts.insert(batch_id_limit.to_string(), writer.max_retries);
        }

        // è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ååº”è¯¥æ‹’ç»é‡è¯•
        assert!(
            !writer
                .should_retry_batch(&test_batch, &database_error, batch_id_limit)
                .await
        );
    }

    #[tokio::test]
    async fn test_requeue_batch() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        let test_events = vec![create_test_event(), create_test_event(), create_test_event()];

        // é‡æ–°æ’é˜Ÿäº‹ä»¶
        writer.requeue_batch(test_events.clone()).await;

        // éªŒè¯äº‹ä»¶å·²æ·»åŠ åˆ°ç¼“å†²åŒº
        let buffer_size = {
            let buffer = writer.event_buffer.lock().await;
            buffer.len()
        };
        assert_eq!(buffer_size, test_events.len());
    }

    #[tokio::test]
    async fn test_batch_writer_stats() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        // æ¨¡æ‹Ÿä¸€äº›ç»Ÿè®¡æ•°æ®
        writer.events_written.store(10, Ordering::Relaxed);
        writer.events_failed.store(2, Ordering::Relaxed);
        writer.batches_written.store(3, Ordering::Relaxed);

        let stats = writer.get_stats().await;
        assert_eq!(stats.events_written, 10);
        assert_eq!(stats.events_failed, 2);
        assert_eq!(stats.batches_written, 3);
        assert_eq!(stats.success_rate, 10.0 / 12.0);
        assert_eq!(stats.average_batch_size, 10.0 / 3.0);
    }

    #[tokio::test]
    async fn test_is_healthy() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        // æœªè¿è¡Œæ—¶ä¸å¥åº·
        assert!(!writer.is_healthy().await);

        // è¿è¡Œæ—¶å¥åº·
        writer.is_running.store(true, Ordering::Relaxed);
        assert!(writer.is_healthy().await);
    }

    #[tokio::test]
    async fn test_reset_stats() {
        let config = create_test_config();
        let writer = BatchWriter::new(&config).await.unwrap();

        // è®¾ç½®ä¸€äº›ç»Ÿè®¡æ•°æ®
        writer.events_written.store(10, Ordering::Relaxed);
        writer.events_failed.store(2, Ordering::Relaxed);

        writer.reset_stats().await;

        let stats = writer.get_stats().await;
        assert_eq!(stats.events_written, 0);
        assert_eq!(stats.events_failed, 0);
    }
}
